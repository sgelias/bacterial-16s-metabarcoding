# Bacterial 16S metabarcoding pipeline
#
# @sgelias
#
# Description: Perform quality checks, generate quality reporter, and perform 
# taxonomic annotation for bacterial 16S metabarcoding sequencing product. See 
# README.md file for details.


# Import the configuration file.
configfile: "config.yaml"


# Set the auxiliary variables to be used along the pipeline.
## The suffix indicate the file format as output of the fastqc quality reporter.
SUFFIX = ["fastqc.zip", "fastqc.html"]

## Specify the constant of the config file that contain all the sample names.
FILES = config["samples"]


"""
Step: Connect all pipeline outputs.
"""


rule all:
    input:
        expand(
            "{directory}/{file}_{suffix}",
            directory=config["fastq_raw_quality"],
            file=FILES,
            suffix=SUFFIX,
        ),
        expand(
            "{directory}/{file}_FILTERED_{suffix}",
            directory=config["fastq_trimmed_quality"],
            file=FILES,
            suffix=SUFFIX,
        ),
        "{directory}/{file}".format(
            directory=config["otu_table"], 
            file="otu_table.tsv"
        ),


"""
Step: Generate quality score reports from raw sequences.
Software: FastQC
Version: 0.11.5
Description: Read a set of sequence files and generate individual quality 
reports.
"""


rule generate_quality_scores_raw:
    message:
        """--- Quality check of raw data with Fastqc."""
    input:
        expand(
            "{directory}/{file}.fastq", 
            directory=config["fastq_raw"], 
            file=FILES,
        ),
    output:
        expand(
            "{directory}/{file}_{suffix}",
            directory=config["fastq_raw_quality"],
            file=FILES,
            suffix=SUFFIX,
        ),
    log:
        config["fastq_raw_quality_log"],
    params:
        output_dir=config["fastq_raw_quality"],
    threads: 2
    shell:
        """
        mkdir -p {params.output_dir}
        fastqc -q \
            --outdir {params.output_dir} \
            --threads {threads} \
            {input} \
            &>> {log}
        """


"""
Step: Trim end's of fastq files.
Software: Trimmomatic
Version: 0.39
Description: Remove low quality end's of raw sequences given some filters.

Important parameters:
    ILLUMINACLIP: Specify the adapters file. A default Trimmomatic includes a 
    set of fasta files containing default adapters. To change the set of 
    adapters for each one, simple specify the `adapters` at the config.yaml 
    file.
    HEADCROP: Remove bases from the beginning of reads that not reaching a 
    minimmun quality score.
    SLIDINGWINDOW: Perform a sliding window trimming, removing bases if the 
    average quality within do not reaches a threshold.
    MINLEN: Remove sequences that falls to reach a mimimun length after apply 
    all quality filters.
"""


rule trim_se:
    message:
        """--- Trimming raw data with Trimmomatic."""
    input:
        expand(
            "{directory}/{file}.fastq", 
            directory=config["fastq_raw"], 
            file=FILES,
        ),
    output:
        expand(
            "{directory}/{file}_FILTERED.fastq",
            directory=config["fastq_trimmed"],
            file=FILES,
        ),
    log:
        config["fastq_trimmed_log"],
    params:
        headcrop=20,
        slidingwindow="5:20",
        minlen=180,
        adapters="{adapters}:2:30:10".format(adapters=config["adapters"]),
        trimmomatic=config["trimmomatic"],
        workdir=config["fastq_trimmed"],
    threads: 2
    run:
        for file in input:

            filename = file.split("/")[-1].split(".")[0]

            target_output = [
                item for item in output if item \
                    .split("/")[-1] \
                    .startswith(filename)
            ]

            shell(
                """
                mkdir -p {params.workdir}
                java -jar {params.trimmomatic} \
                    SE -phred33 \
                    -threads {threads} \
                    {file} \
                    {target_output} \
                    ILLUMINACLIP:"{params.adapters}" \
                    HEADCROP:{params.headcrop} \
                    SLIDINGWINDOW:{params.slidingwindow} \
                    MINLEN:{params.minlen} \
                    &>> {log}
                """
            )


"""
Step: Generate quality score reports from trimmed sequences.
Software: FastQC
Version: 0.11.5
Description: Read a set of sequence files and generate individual quality 
reports.
"""


rule generate_quality_scores_trimmed:
    message:
        """--- Quality check of trimmed data with Fastqc."""
    input:
        trimmed_files=rules.trim_se.output,
    output:
        expand(
            "{directory}/{file}_FILTERED_{suffix}",
            directory=config["fastq_trimmed_quality"],
            file=FILES,
            suffix=SUFFIX,
        ),
    log:
        config["fastq_trimmed_quality_log"],
    params:
        output_dir=config["fastq_trimmed_quality"],
    threads: 4
    shell:
        """
        mkdir -p {params.output_dir}
        fastqc -q \
            --outdir {params.output_dir} \
            --threads {threads} \
            {input} \
            &>> {log}
        """


"""
Step: Build a reference database given a entry fasta.
Software: makeblastdb (from BLASTn)
Version: 2.6.0
Description: Build a reference database use in blastn step (next step).
"""


rule build_reference_database:
    message:
        """--- Building reference database."""
    input:
        config["reference"],
    output:
        expand(
            "{output_dir}/{output_prefix}.{blast_database_formats}",
            output_dir=config["reference_blast"],
            output_prefix="bacterial_16S",
            blast_database_formats=["nhr", "nin", "nsq"],
        ),
    params:
        dbtype="nucl",
        output_dir=config["reference_blast"],
        output_prefix="bacterial_16S",
    shell:
        """
        mkdir -p {params.output_dir}
        makeblastdb \
            -in {input} \
            -dbtype {params.dbtype} \
            -out {params.output_dir}/{params.output_prefix}
        """


"""
Step: Convert trimmed fastq files to simple fasta files.
Software: sed
Version: 4.4
Description: Convert trimmed fastq files to simple fasta files.
"""


rule convert_fastq_to_fasta:
    message:
        """--- Convert FASTQ to FASTA fromat."""
    input:
        expand(
            "{directory}/{file}_FILTERED.fastq",
            directory=config["fastq_trimmed"],
            file=FILES,
        ),
    output:
        expand(
            "{directory}/{file}_FILTERED.fasta",
            directory=config["fasta_trimmed"],
            file=FILES,
        ),
    run:
        for file in input:

            filename = file.split("/")[-1].split(".")[0]

            target_output = [
                item for item in output if item \
                    .split("/")[-1] \
                    .startswith(filename)
            ][0]

            shell(
                """
                sed -n '1~4s/^@/>/p;2~4p' \
                    {file} > {target_output}
                """
            )


"""
Step: Search sequences match from a reference database (subject sequences).
Software: blastn (from BLASTn)
Version: 2.6.0
Description: Perform query-subject matches to compare with a reference database
build at the previous step (the reference database build using the makeblastdb)
method.
"""


rule perform_taxonomic_annotation:
    message:
        """--- Taxonomic annotation using blastn."""
    input:
        trimmed_files=rules.convert_fastq_to_fasta.output,
        reference_database=rules.build_reference_database.output,
    output:
        expand(
            "{directory}/{file}_FILTERED_BAC16S.csv",
            directory=config["tax_annotation"],
            file=FILES,
        ),
    params:
        evalue=1e-5,
        outfmt="10",
        max_target_seqs=50,
        perc_identity=0.95,
        max_hsps=50,
        db=rules.build_reference_database.params.output_prefix,
        db_dir=config["reference_blast"],
        output_dir=config["tax_annotation"],
    threads: 4
    run:
        for file in input.trimmed_files:

            filename = file.split("/")[-1].split(".")[0]

            target_output = [
                item for item in output if item \
                    .split("/")[-1] \
                    .startswith(filename)
            ][0]

            shell(
                """
                mkdir -p {params.output_dir}
                cd {params.output_dir}
                blastn \
                    -query {file} \
                    -evalue {params.evalue} \
                    -outfmt {params.outfmt} \
                    -num_threads {threads} \
                    -max_target_seqs {params.max_target_seqs} \
                    -perc_identity {params.perc_identity} \
                    -max_hsps {params.max_hsps} \
                    -db {params.db_dir}/{params.db} \
                    -out {target_output}
                """
            )


"""
Step: Generate OTU by sample count table.
Software: In house Python script.
Version: ---
Description: Convert BLASTn tabular results to a count by sample TSV table.

Important parameters:
    blastdir: The directory containing all TSV blast results as the entry for 
    the algorithm.
    outputdir: The directory so save the output file.
    reference_database: The FASTA file used as reference for the sequences 
    annotation using BLASTn. Used to retriave the full subject description.
    cut_suffix: A string to be removed from each sample name. It is a optional 
    parameter, but is usefull in cases in with the names of sequence files 
    including aditional names included during the pipeline previous steps.
"""


rule generate_count_table:
    message:
        """--- Generating taxon by sample count table."""
    input:
        rules.perform_taxonomic_annotation.output,
    output:
        "{directory}/{file}".format(
            directory=config["otu_table"], 
            file="otu_table.tsv"
        ),
    params:
        blast_dir=config["tax_annotation"],
        output_dir=config["otu_table"],
        reference_database=config["reference"],
        cut_suffix="",
        builder=config["otu_table_builder"],
    shell:
        """
        mkdir -p {params.output_dir}
        python {params.builder} \
            --blastdir {params.blast_dir} \
            --outputdir {params.output_dir}/otu_table.tsv \
            --reference_database {params.reference_database} \
            --cut_suffix '_L001_R1_001_FILTERED_BAC16S'
        """
